{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPsYytskBK1le4bCQCd7h/J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Pre-request**"],"metadata":{"id":"ciuB8qbujuUK"}},{"cell_type":"markdown","source":["##Mount google drive\n"],"metadata":{"id":"URXspYqinKvz"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Y3jalBfTYDd1","executionInfo":{"status":"ok","timestamp":1760187501029,"user_tz":-180,"elapsed":2236,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2a3e4f0-78c6-4c4b-ca03-8de429111eb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["### **Mount** Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["##Install pakages\n"],"metadata":{"id":"CvlwvbLJnAnt"}},{"cell_type":"code","source":["#Install pakages\n","%pip install -q -r /content/drive/MyDrive/Sem-6/coding/github/fraud_detection/Extract_requirements.txt --no-cache-dir\n","\n"],"metadata":{"id":"T5jrMcMxnBbd","executionInfo":{"status":"ok","timestamp":1760187506981,"user_tz":-180,"elapsed":5958,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["project_path = \"/content/drive/MyDrive/Sem-6/coding/github/fraud_detection/\"\n","%cd $project_path\n","%ls /content/drive/MyDrive/Sem-6/coding/github/fraud_detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqAY-whCYfGa","executionInfo":{"status":"ok","timestamp":1760187507076,"user_tz":-180,"elapsed":94,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}},"outputId":"1f5a072c-7b7e-4a39-b631-8be9d082832b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Sem-6/coding/github/fraud_detection\n","clustring_requirements-lock.txt  requirements-lock.txt\n","clustring_requirements.txt       requirements.txt\n","\u001b[0m\u001b[01;34mconfigs\u001b[0m/                         \u001b[01;34mresults\u001b[0m/\n","\u001b[01;34mdataset\u001b[0m/                         run_experiment.py\n","Extract_requirements-lock.txt    sample_extract_requirements-lock.txt\n","Extract_requirements.txt         \u001b[01;34msrc\u001b[0m/\n","\u001b[01;34mnotebooks\u001b[0m/                       \u001b[01;34mtests\u001b[0m/\n","README.md\n"]}]},{"cell_type":"markdown","source":["##Import  libs"],"metadata":{"id":"WvyLM3QTbd_i"}},{"cell_type":"code","source":["\n","import datetime\n","import os\n","import pandas as pd\n","import numpy as np\n","from scipy.stats import mode\n","import yaml\n","import logging\n","from tqdm import tqdm\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.manifold import TSNE\n","import altair as alt\n","from google.colab import data_table\n","data_table.enable_dataframe_formatter()\n","# Expand Colabâ€™s table display limits\n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.width\", None)\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from datetime import timedelta\n","\n","\n","%pip freeze > Extract_requirements-lock.txt\n"],"metadata":{"id":"FPNLoT_Ebi-V","executionInfo":{"status":"ok","timestamp":1760187515727,"user_tz":-180,"elapsed":8648,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["#Utility Functions"],"metadata":{"id":"NnzjuFu9Zkxv"}},{"cell_type":"markdown","source":["##Loging"],"metadata":{"id":"7nRzKih-cqxq"}},{"cell_type":"code","source":["\n","# Make sure results directory exists\n","os.makedirs(\"results\", exist_ok=True)\n","\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n","    handlers=[\n","        logging.StreamHandler(),\n","        logging.FileHandler(\"results/data_extract.log\")\n","    ]\n",")\n","logger = logging.getLogger(__name__)\n","\n"],"metadata":{"id":"pGzp5RbmcsRe","executionInfo":{"status":"ok","timestamp":1760187515755,"user_tz":-180,"elapsed":26,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["##Config"],"metadata":{"id":"d87bKwsNbtwZ"}},{"cell_type":"code","source":["def load_config(config_path=\"configs/baseline.yaml\"):\n","    \"\"\"Load YAML config file.\"\"\"\n","    with open(config_path, \"r\") as f:\n","        config = yaml.safe_load(f)\n","    logger.info(f\"âœ… Loaded config from {config_path}\")\n","    return config\n"],"metadata":{"id":"Hhoop6PFbv4D","executionInfo":{"status":"ok","timestamp":1760187515807,"user_tz":-180,"elapsed":26,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## CDR dataset"],"metadata":{"id":"TvvDiG09bzCk"}},{"cell_type":"code","source":["def load_cdr(file_path, nrows=None):\n","    \"\"\"Load a CSV file and safely parse datetime columns.\"\"\"\n","    logger.info(f\"ðŸ“‚ Loading file: {file_path} (nrows={nrows})\")\n","    df = pd.read_csv(file_path, nrows=nrows)\n","\n","    # Auto-detect and parse datetime columns\n","    for col in df.columns:\n","        if \"datetime\" in col.lower() or \"time\" in col.lower():\n","            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n","\n","    df.columns = df.columns.str.strip()  # clean header spaces\n","    logger.info(f\"âœ… Loaded {df.shape[0]} rows, {df.shape[1]} columns\")\n","    return df\n","\n","\n","def load_all_data(config):\n","    \"\"\"\n","    Load all CSVs defined in config['Agg'] into a dict of DataFrames.\n","    \"\"\"\n","    agg_cfg = config[\"Agg\"]\n","    base = agg_cfg[\"base_path\"]\n","    files = agg_cfg[\"files\"]\n","\n","    data = {}\n","    for name, fname in files.items():\n","        path = os.path.join(base, fname)\n","        df = load_cdr(path)\n","        data[name] = df\n","        logger.info(f\"ðŸ“Š Loaded {name:<5} -> {df.shape} from {path}\")\n","    return data"],"metadata":{"id":"Xr2pQYTbb0__","executionInfo":{"status":"ok","timestamp":1760187515861,"user_tz":-180,"elapsed":26,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["##Features"],"metadata":{"id":"p9tri6o1ihJy"}},{"cell_type":"markdown","source":["###Voice Features"],"metadata":{"id":"IaF88qlPijo7"}},{"cell_type":"code","source":["def get_voc_feats(df, cutoff_time=None, n_events=None):\n","    \"\"\"Extract per-user voice call features within given time window.\"\"\"\n","    df = df.copy()\n","    if df.empty:\n","        return pd.DataFrame(columns=[\"phone_no_m\"])\n","\n","    # âœ… Time filtering (moved from build_user_snapshots)\n","    if cutoff_time is not None:\n","        df = df[df[\"start_datetime\"] >= cutoff_time]\n","    if n_events:\n","        df = df.sort_values(\"start_datetime\").tail(n_events)\n","\n","    df[\"call_dur\"] = pd.to_numeric(df[\"call_dur\"], errors=\"coerce\").fillna(0)\n","\n","    df[\"weekday\"] = pd.to_datetime(df[\"start_datetime\"]).dt.weekday\n","    df[\"hour\"] = pd.to_datetime(df[\"start_datetime\"]).dt.hour\n","\n","    feats = (\n","        df.groupby(\"phone_no_m\", as_index=False)\n","        .agg(\n","            voc_total_calls=(\"start_datetime\", \"count\"),\n","            voc_unique_contacts=(\"opposite_no_m\", \"nunique\"),\n","            voc_total_duration=(\"call_dur\", \"sum\"),\n","            voc_avg_duration=(\"call_dur\", \"mean\"),\n","            voc_max_duration=(\"call_dur\", \"max\"),\n","            voc_std_duration=(\"call_dur\", \"std\"),\n","            voc_active_days=(\"weekday\", \"nunique\"),\n","            voc_active_hours=(\"hour\", \"nunique\"),\n","        )\n","    )\n","    return feats.fillna(0)\n"],"metadata":{"id":"vXwZ4jHYikyu","executionInfo":{"status":"ok","timestamp":1760187515891,"user_tz":-180,"elapsed":28,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["###SMS Features"],"metadata":{"id":"P9Cf5_xKisd6"}},{"cell_type":"code","source":["def get_sms_feats(df, cutoff_time=None, n_events=None):\n","    \"\"\"Extract per-user SMS features within given time window.\"\"\"\n","    df = df.copy()\n","    if df.empty:\n","        return pd.DataFrame(columns=[\"phone_no_m\"])\n","\n","    # âœ… Time filtering (if requested)\n","    if cutoff_time is not None:\n","        df = df[df[\"request_datetime\"] >= cutoff_time]\n","    if n_events:\n","        df = df.sort_values(\"request_datetime\").tail(n_events)\n","\n","    # âœ… Ensure calltype_id is numeric\n","    df[\"calltype_id\"] = pd.to_numeric(df[\"calltype_id\"], errors=\"coerce\")\n","\n","    # âœ… Extract hour for time-based features\n","    df[\"hour\"] = pd.to_datetime(df[\"request_datetime\"]).dt.hour\n","\n","    feats = (\n","        df.groupby(\"phone_no_m\", as_index=False)\n","        .agg(\n","            sms_total_msgs=(\"request_datetime\", \"count\"),\n","            sms_unique_contacts=(\"opposite_no_m\", \"nunique\"),\n","            sms_active_hours=(\"hour\", \"nunique\"),\n","            # 1 â†’ outgoing, 2 â†’ incoming (adjust if opposite)\n","            sms_calltype_ratio=(\"calltype_id\", lambda x: (x == 1).mean()),\n","        )\n","    )\n","\n","    return feats.fillna(0)\n"],"metadata":{"id":"cweWK-htitTC","executionInfo":{"status":"ok","timestamp":1760187515940,"user_tz":-180,"elapsed":47,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["###App Features"],"metadata":{"id":"AvK7i9pgivbT"}},{"cell_type":"code","source":["import pandas as pd\n","import datetime\n","\n","def get_app_feats(df):\n","    \"\"\"Extract per-user application usage features (aggregated monthly).\n","    Handles various month_id formats internally (201908, '2019-08', '2019/08', '2019-12-01').\n","    \"\"\"\n","    df = df.copy()\n","\n","    if df.empty:\n","        return pd.DataFrame(columns=[\n","            \"phone_no_m\", \"app_months_active\", \"app_total_flow\",\n","            \"app_avg_flow\", \"app_std_flow\",\n","            \"app_unique_apps_mean\", \"app_unique_apps_max\"\n","        ])\n","\n","    # Ensure month_id exists\n","    if \"month_id\" not in df.columns:\n","        raise ValueError(\"âŒ APP dataset must contain 'month_id' column.\")\n","\n","    # Convert flow to numeric\n","    df[\"flow\"] = pd.to_numeric(df[\"flow\"], errors=\"coerce\").fillna(0)\n","\n","    # Inline month_id parser\n","    def parse_month_end(x):\n","        if pd.isna(x):\n","            return pd.NaT\n","        s = str(x).strip()\n","        # Handle YYYYMM\n","        if s.isdigit() and len(s) == 6:\n","            y, m = int(s[:4]), int(s[4:])\n","            return pd.Timestamp(datetime.date(y, m, 1)) + pd.offsets.MonthEnd(0)\n","        # Handle full or partial date strings\n","        for fmt_try in [s, s + \"-01\"]:\n","            try:\n","                dt = pd.to_datetime(fmt_try, errors=\"coerce\")\n","                if pd.notna(dt):\n","                    return dt + pd.offsets.MonthEnd(0)\n","            except Exception:\n","                continue\n","        return pd.NaT\n","\n","    # Apply month parsing\n","    df[\"month_end\"] = df[\"month_id\"].apply(parse_month_end)\n","    df = df.dropna(subset=[\"month_end\"])\n","\n","    # Aggregate monthly totals\n","    monthly = (\n","        df.groupby([\"phone_no_m\", \"month_end\"])\n","        .agg(\n","            total_flow=(\"flow\", \"sum\"),\n","            unique_apps=(\"busi_name\", \"nunique\"),\n","        )\n","        .reset_index()\n","    )\n","\n","    # Aggregate per-user statistics\n","    features = (\n","        monthly.groupby(\"phone_no_m\")\n","        .agg(\n","            app_months_active=(\"month_end\", \"nunique\"),\n","            app_total_flow=(\"total_flow\", \"sum\"),\n","            app_avg_flow=(\"total_flow\", \"mean\"),\n","            app_std_flow=(\"total_flow\", \"std\"),\n","            app_unique_apps_mean=(\"unique_apps\", \"mean\"),\n","            app_unique_apps_max=(\"unique_apps\", \"max\"),\n","        )\n","        .reset_index()\n","        .fillna(0)\n","    )\n","\n","    return features\n"],"metadata":{"id":"QTjTAAqFiyWA","executionInfo":{"status":"ok","timestamp":1760187515948,"user_tz":-180,"elapsed":8,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["###User Features"],"metadata":{"id":"toljQbari1no"}},{"cell_type":"code","source":["def get_user_feats(df):\n","    \"\"\"\n","    Extract per-user ARPU-based features.\n","    Handles both YYYYMM and YYYY-MM-DD month_id formats.\n","    Zeros are considered inactive unless explicitly kept.\n","    \"\"\"\n","\n","    import pandas as pd\n","    df = df.copy()\n","\n","    if \"arpu_value\" not in df.columns:\n","        raise ValueError(\"Expected column 'arpu_value' not found.\")\n","\n","    # --- Convert month_id to datetime safely ---\n","    def to_month_end(val):\n","        if pd.isna(val):\n","            return pd.NaT\n","        s = str(val).strip()\n","        # Handle both '2019-08-01' and '201908'\n","        try:\n","            dt = pd.to_datetime(s, errors=\"coerce\")\n","            if pd.notna(dt):\n","                return dt + pd.offsets.MonthEnd(0)\n","        except Exception:\n","            pass\n","        # fallback for YYYYMM numeric\n","        s = s.replace(\"-\", \"\").replace(\"/\", \"\")\n","        if len(s) == 6:\n","            try:\n","                return pd.to_datetime(s + \"01\", format=\"%Y%m%d\") + pd.offsets.MonthEnd(0)\n","            except Exception:\n","                return pd.NaT\n","        return pd.NaT\n","\n","    df[\"month_end\"] = df[\"month_id\"].apply(to_month_end)\n","\n","    # --- Convert ARPU values to numeric ---\n","    df[\"arpu_value\"] = pd.to_numeric(df[\"arpu_value\"], errors=\"coerce\")\n","\n","    # --- Filter valid ARPU entries ---\n","    df_valid = df[df[\"arpu_value\"].notna() & (df[\"arpu_value\"] > 0)]\n","\n","    # --- Aggregate per user ---\n","    user_feats = (\n","        df_valid.groupby(\"phone_no_m\", as_index=False)\n","        .agg(\n","            user_months_active=(\"month_end\", \"nunique\"),\n","            arpu_mean=(\"arpu_value\", \"mean\"),\n","            arpu_std=(\"arpu_value\", \"std\"),\n","            arpu_max=(\"arpu_value\", \"max\"),\n","            idcard_cnt=(\"idcard_cnt\", \"max\"),\n","            label=(\"label\", \"max\"),\n","        )\n","    )\n","\n","    # --- If no active month found, return zero row ---\n","    if user_feats.empty:\n","        user_feats = pd.DataFrame([{\n","            \"phone_no_m\": df[\"phone_no_m\"].iloc[0],\n","            \"user_months_active\": 0,\n","            \"arpu_mean\": 0,\n","            \"arpu_std\": 0,\n","            \"arpu_max\": 0,\n","            \"idcard_cnt\": df.get(\"idcard_cnt\", [0])[0],\n","            \"label\": df.get(\"label\", [0])[0],\n","        }])\n","\n","    return user_feats\n"],"metadata":{"id":"odhG-vnmi4F-","executionInfo":{"status":"ok","timestamp":1760187515966,"user_tz":-180,"elapsed":15,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["###Get feature names"],"metadata":{"id":"MMukuCrAFYel"}},{"cell_type":"code","source":["def get_feature_names():\n","    ALL_FEATURE_COLUMNS = [\n","        # Voice\n","        \"voc_total_calls\", \"voc_unique_contacts\", \"voc_total_duration\",\n","        \"voc_avg_duration\", \"voc_max_duration\", \"voc_std_duration\",\n","        \"voc_active_days\", \"voc_active_hours\",\n","        # SMS\n","        \"sms_total_msgs\", \"sms_unique_contacts\", \"sms_active_hours\", \"sms_calltype_ratio\",\n","        # App\n","        \"app_months_active\", \"app_total_flow\", \"app_avg_flow\",\n","        \"app_std_flow\", \"app_unique_apps_mean\", \"app_unique_apps_max\",\n","        # User / ARPU\n","        \"user_months_active\", \"arpu_mean\", \"arpu_std\", \"arpu_max\",\n","        \"idcard_cnt\", \"label\"\n","    ]\n","    return ALL_FEATURE_COLUMNS\n"],"metadata":{"id":"y_hPuwI-Fa-t","executionInfo":{"status":"ok","timestamp":1760187515996,"user_tz":-180,"elapsed":27,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["###App Risk Level"],"metadata":{"id":"OgODZqVji8cy"}},{"cell_type":"code","source":["def compute_app_risk_levels(df, label_col=\"label\", min_users=5):\n","    \"\"\"Compute fraud risk ratio per app.\"\"\"\n","    if df.empty or label_col not in df.columns:\n","        return pd.DataFrame(columns=[\"busi_name\", \"risk_level\", \"fraud_ratio\"])\n","\n","    risk_df = (\n","        df.groupby(\"busi_name\", as_index=False)\n","        .agg(\n","            users=(\"phone_no_m\", \"nunique\"),\n","            fraud_users=(label_col, \"sum\"),\n","        )\n","    )\n","    risk_df[\"fraud_ratio\"] = risk_df[\"fraud_users\"] / risk_df[\"users\"]\n","    risk_df = risk_df[risk_df[\"users\"] >= min_users]\n","\n","    # Risk level classification\n","    bins = [0, 0.01, 0.05, 0.15, 0.30, 1.0]\n","    labels = [\"Low\", \"Medium\", \"Elevated\", \"High\", \"Critical\"]\n","    risk_df[\"risk_level\"] = pd.cut(risk_df[\"fraud_ratio\"], bins=bins, labels=labels)\n","\n","    return risk_df"],"metadata":{"id":"KvndReoAi_SL","executionInfo":{"status":"ok","timestamp":1760187516002,"user_tz":-180,"elapsed":4,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["##Snapshot"],"metadata":{"id":"LkjmaayJdyE7"}},{"cell_type":"markdown","source":["###ensure dataframe"],"metadata":{"id":"FPpmqkpyFLtP"}},{"cell_type":"code","source":["\n","def ensure_dataframe(df, label, user):\n","    \"\"\"Guarantee a DataFrame with phone_no_m even if empty or Series.\"\"\"\n","    if df is None:\n","        df = pd.DataFrame()\n","    if isinstance(df, pd.Series):\n","        df = df.to_frame().T\n","    if not isinstance(df, pd.DataFrame):\n","        df = pd.DataFrame(df)\n","    if df.empty or \"phone_no_m\" not in df.columns:\n","        df[\"phone_no_m\"] = [user]\n","    return df.reset_index(drop=True)\n","\n"],"metadata":{"id":"DrLLEx2nFNWh","executionInfo":{"status":"ok","timestamp":1760187516026,"user_tz":-180,"elapsed":21,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["###Subset by window"],"metadata":{"id":"zq9t9lgoW6rC"}},{"cell_type":"code","source":["def subset_by_window(df, times):\n","    return df[df[\"event_time\"].isin(times)]\n"],"metadata":{"id":"JTxZqTuvW75y","executionInfo":{"status":"ok","timestamp":1760187516056,"user_tz":-180,"elapsed":32,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["###Build snapshot windows"],"metadata":{"id":"gpBbObr9Rz2H"}},{"cell_type":"code","source":["def build_snapshot_windows(all_user_events, event_times_sorted, user_min_time, user_max_time, window_mode, window_size,max_snapshots=1):\n","    \"\"\"Generate time- or event-based snapshot windows for a single user.\"\"\"\n","    snapshots_for_user = []\n","\n","    if window_mode == \"time\":\n","        cutoff_time = user_min_time + datetime.timedelta(days=window_size)\n","\n","        print(f\"\\n Cutoff is {cutoff_time} for first snapshot\\n\")\n","\n","        while True:\n","            start_window = cutoff_time - datetime.timedelta(days=window_size)\n","\n","            recent_events = all_user_events[\n","                (all_user_events[\"event_time\"] >= start_window) &\n","                (all_user_events[\"event_time\"] <= cutoff_time)\n","            ].copy()\n","\n","            print(f\"Checking {start_window} â†’ {cutoff_time}: {len(recent_events)} events\")\n","\n","            if not recent_events.empty:\n","                snapshots_for_user.append((start_window, cutoff_time, recent_events))\n","\n","            # stop when window start exceeds last event\n","            if start_window > user_max_time:\n","                break\n","          # âœ… Stop if we've reached max snapshots\n","            if max_snapshots and len(snapshots_for_user) >= max_snapshots:\n","                  break\n","\n","\n","            cutoff_time += datetime.timedelta(days=1)\n","\n","    elif window_mode == \"events\":\n","        total_events = len(event_times_sorted)\n","        if total_events >= window_size:\n","            for start_idx in range(0, total_events - window_size + 1, 1):  # sliding by 1\n","                end_idx = start_idx + window_size\n","                recent_events = all_user_events.iloc[start_idx:end_idx].copy()\n","                cutoff_time = recent_events[\"event_time\"].max()\n","                start_window = recent_events[\"event_time\"].min()\n","                print(f\"Checking events {start_idx}â€“{end_idx}: {len(recent_events)} records | {start_window} â†’ {cutoff_time}\")\n","                snapshots_for_user.append((start_window, cutoff_time, recent_events))\n","                    # âœ… Stop after X snapshots if user requested\n","                if max_snapshots and len(snapshots_for_user) >= max_snapshots:\n","                      break\n","        else:\n","            cutoff_time = event_times_sorted[-1]\n","            recent_events = all_user_events.copy()\n","            start_window = event_times_sorted[0]\n","            print(f\"Checking all {len(recent_events)} records | {start_window} â†’ {cutoff_time}\")\n","            snapshots_for_user.append((start_window, cutoff_time, recent_events))\n","\n","    else:\n","        raise ValueError(\"Invalid window_mode: must be 'time' or 'events'\")\n","\n","    # filter empty windows before returning\n","    snapshots_for_user = [s for s in snapshots_for_user if not s[2].empty]\n","    return snapshots_for_user\n"],"metadata":{"id":"d91e3AzCR5j0","executionInfo":{"status":"ok","timestamp":1760188851683,"user_tz":-180,"elapsed":11,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["###Get event type"],"metadata":{"id":"qavO-x3hY7wf"}},{"cell_type":"code","source":["def get_event_type_for_cutoff(all_user_events, cutoff_time):\n","    \"\"\"Return the source type of the last event before or at cutoff_time.\"\"\"\n","    match_row = all_user_events.query(\"event_time <= @cutoff_time\").tail(1)\n","    return match_row[\"source\"].iloc[0] if not match_row.empty else \"Unknown\"\n"],"metadata":{"id":"i-7HC-wvY67u","executionInfo":{"status":"ok","timestamp":1760187516106,"user_tz":-180,"elapsed":27,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["###Subset per source"],"metadata":{"id":"1F2TOWEZY_1j"}},{"cell_type":"code","source":["def split_events_by_source(voc_user, sms_user, app_user, arpu_user, recent_events):\n","    \"\"\"Return per-source event subsets for the given window.\"\"\"\n","    times_in_window = set(recent_events[\"event_time\"])\n","    return {\n","        \"VOC\": subset_by_window(voc_user, times_in_window),\n","        \"SMS\": subset_by_window(sms_user, times_in_window),\n","        \"APP\": subset_by_window(app_user, times_in_window),\n","        \"ARPU\": subset_by_window(arpu_user, times_in_window),\n","    }\n"],"metadata":{"id":"wD-yui6ZZDJN","executionInfo":{"status":"ok","timestamp":1760187516127,"user_tz":-180,"elapsed":19,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["###Feature extraction wrapper"],"metadata":{"id":"sByOrpi4ZFrO"}},{"cell_type":"code","source":["def extract_features_for_sources(subsets, user):\n","    \"\"\"Run feature extraction for each data source safely.\"\"\"\n","    feats = {}\n","    try:\n","        feats[\"USER\"] = get_user_feats(subsets[\"ARPU\"]) if not subsets[\"ARPU\"].empty else pd.DataFrame()\n","        feats[\"VOC\"]  = get_voc_feats(subsets[\"VOC\"])   if not subsets[\"VOC\"].empty else pd.DataFrame()\n","        feats[\"SMS\"]  = get_sms_feats(subsets[\"SMS\"])   if not subsets[\"SMS\"].empty else pd.DataFrame()\n","        feats[\"APP\"]  = get_app_feats(subsets[\"APP\"])   if not subsets[\"APP\"].empty else pd.DataFrame()\n","    except Exception as e:\n","        print(f\"âŒ Feature extraction failed for user {user}: {e}\")\n","        return {}\n","\n","    # Ensure dataframes are valid and have phone_no_m\n","    for key in feats:\n","        feats[key] = ensure_dataframe(feats[key], key.lower(), user)\n","    return feats\n"],"metadata":{"id":"TcjF8NBiZKgf","executionInfo":{"status":"ok","timestamp":1760187516132,"user_tz":-180,"elapsed":2,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["###Combine to single snapshot row"],"metadata":{"id":"Ih5MlkeLZQ8g"}},{"cell_type":"code","source":["def combine_features_to_snapshot(\n","    user, step, cutoff_time, event_type,\n","    window_mode, window_size, feats, all_feature_columns,start_window\n","):\n","    \"\"\"Merge all per-source features into one unified snapshot row.\"\"\"\n","    base = pd.DataFrame({\n","        \"phone_no_m\": [user],\n","        \"snapshot_index\": [step],\n","        \"timeframe_start\": [start_window],\n","        \"timeframe_end\": [cutoff_time],\n","        \"last_event_type\": [event_type],\n","        \"window_mode\": [window_mode],\n","        \"window_size\": [window_size],\n","    })\n","\n","    snapshot = (\n","        base\n","        .merge(feats.get(\"VOC\", pd.DataFrame()), on=\"phone_no_m\", how=\"left\")\n","        .merge(feats.get(\"SMS\", pd.DataFrame()), on=\"phone_no_m\", how=\"left\")\n","        .merge(feats.get(\"APP\", pd.DataFrame()), on=\"phone_no_m\", how=\"left\")\n","        .merge(feats.get(\"USER\", pd.DataFrame()), on=\"phone_no_m\", how=\"left\")\n","    )\n","\n","    snapshot = snapshot.reindex(\n","        columns=[\n","            \"phone_no_m\", \"snapshot_index\", \"timeframe_start\",\"timeframe_end\",\n","            \"last_event_type\", \"window_mode\", \"window_size\"\n","        ] + all_feature_columns,\n","        fill_value=0\n","    )\n","    return snapshot\n"],"metadata":{"id":"yXL-8rm_ZN-C","executionInfo":{"status":"ok","timestamp":1760190667900,"user_tz":-180,"elapsed":68,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":["###Time-Aware User Snapshots"],"metadata":{"id":"ttG_6iA0jDLy"}},{"cell_type":"code","source":["\n","def build_user_snapshots_global(\n","    df_voc,\n","    df_sms,\n","    df_app_tx,\n","    df_arpu_tx,\n","    window_size=30,           # Can be days or number of events\n","    window_mode=\"time\",       # \"time\" or \"events\"\n","    max_snapshots=None,\n","    max_users=None,\n","    save_path=None\n","):\n","\n","\n","\n","    # --- Step 1: Expected feature schema ---\n","    ALL_FEATURE_COLUMNS = get_feature_names()\n","\n","    # --- Step 2: Unified timeline ---\n","    df_timeline = build_unified_timeline(df_voc, df_sms, df_app_tx, df_arpu_tx)\n","    users = sorted(df_timeline[\"phone_no_m\"].unique())\n","    total_available = len(users)\n","    if max_users:\n","        users = users[:max_users]\n","        print(f\"âš™ï¸ Limiting run to first {max_users} users out of {total_available} total.\\n\")\n","\n","    snapshots = []\n","    # --- Step 3: Process each user ---\n","    for user in tqdm(users, desc=\"ðŸ“¸ Building unified snapshots\"):\n","        user_tl = prepare_user_timeline(df_timeline, user)\n","        if user_tl is None:\n","            continue\n","\n","        user_subsets = get_user_subsets(df_voc, df_sms, df_app_tx, df_arpu_tx, user)\n","        all_user_events, user_min_time, user_max_time = build_unified_user_events(user_subsets)\n","\n","        if all_user_events is None:\n","            continue\n","\n","        print(f\"\\n\\nðŸ“… User timeline range: {user_min_time} â†’ {user_max_time}\")\n","\n","\n","        # --- Step 3.2: Build rolling snapshot windows ---\n","        snapshots_for_user = []\n","\n","\n","        event_times_sorted = all_user_events[\"event_time\"].tolist()\n","\n","        snapshots_for_user = build_snapshot_windows(\n","              all_user_events,\n","              event_times_sorted,\n","              user_min_time,\n","              user_max_time,\n","              window_mode,\n","              window_size,\n","              max_snapshots=max_snapshots\n","          )\n","\n","\n","        if not snapshots_for_user:\n","            print(f\"âš ï¸ No valid snapshots for user {user}\")\n","            continue\n","\n","\n","        # --- Step 4: Iterate over each snapshot ---\n","        for step, (start_window, cutoff_time, recent_events) in enumerate(snapshots_for_user, start=1):\n","\n","            # Step 1: Identify event type\n","            event_type = get_event_type_for_cutoff(all_user_events, cutoff_time)\n","\n","            # Step 2: Split per-source subsets\n","            source_subsets = split_events_by_source(\n","              user_subsets[\"VOC\"],\n","              user_subsets[\"SMS\"],\n","              user_subsets[\"APP\"],\n","              user_subsets[\"ARPU\"],\n","              recent_events\n","          )\n","\n","\n","            if all(df.empty for df in source_subsets.values()):\n","                logger.warning(f\"âš ï¸ Skipping empty snapshot for user {user} at {cutoff_time}\")\n","                continue\n","\n","            # Step 3: Extract features safely\n","            feats = extract_features_for_sources(source_subsets, user)\n","\n","            # Step 4: Combine into unified snapshot row\n","            snapshot = combine_features_to_snapshot(\n","                user=user,\n","                step=step,\n","                cutoff_time=cutoff_time,\n","                event_type=event_type,\n","                window_mode=window_mode,\n","                window_size=window_size,\n","                feats=feats,\n","                all_feature_columns=ALL_FEATURE_COLUMNS,\n","                start_window=start_window\n","            )\n","\n","            snapshots.append(snapshot)\n","\n","\n","    # --- Step 5: Combine and Save ---\n","    if not snapshots:\n","        print(\"âš ï¸ No snapshots generated â€” check data or window size.\")\n","        return pd.DataFrame(columns=[\"phone_no_m\"] + ALL_FEATURE_COLUMNS)\n","\n","    tqdm.write(\"\")   # or print(\"\\n\", flush=True)\n","    snapshots_df = pd.concat(snapshots, ignore_index=True).fillna(0)\n","    display(snapshots_df)\n","\n","    return snapshots_df#save_snapshots_to_csv(snapshots_df, save_path, users)\n","\n"],"metadata":{"id":"cqKGPinKjEUB","executionInfo":{"status":"ok","timestamp":1760190429575,"user_tz":-180,"elapsed":48,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["###Build Unified Timeline"],"metadata":{"id":"q3BW4_g-9x-D"}},{"cell_type":"code","source":["def build_unified_timeline(df_voc, df_sms, df_app_tx, df_arpu_tx):\n","    \"\"\"\n","    Build a unified chronological timeline of all user-related events (VOC, SMS, APP, ARPU).\n","    Each entry = (phone_no_m, event_time, source)\n","    \"\"\"\n","    import pandas as pd\n","\n","    def ensure_core_fields(df, name):\n","        \"\"\"Ensure that each dataset has 'phone_no_m', 'event_time', 'source'.\"\"\"\n","        # Fallback for event_time naming\n","        if \"event_time\" not in df.columns:\n","            if \"start_datetime\" in df.columns:\n","                df[\"event_time\"] = pd.to_datetime(df[\"start_datetime\"], errors=\"coerce\")\n","            elif \"request_datetime\" in df.columns:\n","                df[\"event_time\"] = pd.to_datetime(df[\"request_datetime\"], errors=\"coerce\")\n","            else:\n","                raise ValueError(f\"{name} dataset missing a valid timestamp column\")\n","\n","        # Fallback for source naming\n","        if \"source\" not in df.columns:\n","            df[\"source\"] = name\n","\n","        # Keep only relevant columns\n","        df = df[[\"phone_no_m\", \"event_time\", \"source\"]].copy()\n","        df[\"event_time\"] = pd.to_datetime(df[\"event_time\"], errors=\"coerce\")\n","        df = df.dropna(subset=[\"phone_no_m\", \"event_time\"])\n","        return df\n","\n","    # âœ… Normalize all datasets\n","    voc_tl = ensure_core_fields(df_voc, \"VOC\")\n","    sms_tl = ensure_core_fields(df_sms, \"SMS\")\n","    app_tl = ensure_core_fields(df_app_tx, \"APP\")\n","    arpu_tl = ensure_core_fields(df_arpu_tx, \"ARPU\")\n","\n","    # âœ… Combine everything\n","    all_events = pd.concat([voc_tl, sms_tl, app_tl, arpu_tl], ignore_index=True)\n","\n","    # âœ… Sort globally by user and timestamp\n","    all_events = all_events.sort_values([\"phone_no_m\", \"event_time\"]).reset_index(drop=True)\n","\n","    print(f\"ðŸ“¦ Unified timeline built with {len(all_events):,} total events \"\n","          f\"across {all_events['phone_no_m'].nunique()} users.\")\n","    print(all_events['source'].value_counts())\n","\n","    return all_events\n"],"metadata":{"id":"pXr9Uj4o9xEK","executionInfo":{"status":"ok","timestamp":1760187516276,"user_tz":-180,"elapsed":47,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["###Prepare user timeline"],"metadata":{"id":"7WWwWGTvaiio"}},{"cell_type":"code","source":["def prepare_user_timeline(df_timeline, user):\n","    \"\"\"\n","    Extract and clean a user's timeline data (event_time sorted).\n","    Returns: cleaned DataFrame or None if empty.\n","    \"\"\"\n","    user_tl = df_timeline.query(\"phone_no_m == @user\").copy()\n","    if user_tl.empty:\n","        return None\n","\n","    user_tl[\"event_time\"] = pd.to_datetime(user_tl[\"event_time\"], errors=\"coerce\")\n","    user_tl = user_tl.dropna(subset=[\"event_time\"]).sort_values(\"event_time\")\n","    return user_tl if not user_tl.empty else None\n"],"metadata":{"id":"DaenE5ylaf01","executionInfo":{"status":"ok","timestamp":1760187516281,"user_tz":-180,"elapsed":2,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["###Get user subset data"],"metadata":{"id":"jr3Cwj-QaoGQ"}},{"cell_type":"code","source":["def get_user_subsets(df_voc, df_sms, df_app_tx, df_arpu_tx, user):\n","    \"\"\"\n","    Return per-source subsets (VOC, SMS, APP, ARPU) for the given user.\n","    \"\"\"\n","    return {\n","        \"VOC\": df_voc.query(\"phone_no_m == @user\").copy(),\n","        \"SMS\": df_sms.query(\"phone_no_m == @user\").copy(),\n","        \"APP\": df_app_tx.query(\"phone_no_m == @user\").copy(),\n","        \"ARPU\": df_arpu_tx.query(\"phone_no_m == @user\").copy(),\n","    }\n"],"metadata":{"id":"KM8H8-Vtanbq","executionInfo":{"status":"ok","timestamp":1760187516287,"user_tz":-180,"elapsed":2,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["###Build unified user events"],"metadata":{"id":"TSOGk55vatU7"}},{"cell_type":"code","source":["def build_unified_user_events(user_subsets):\n","    \"\"\"\n","    Merge all per-source DataFrames into a single unified chronological event list.\n","    Cleans timestamps and removes NaNs.\n","    Returns: (DataFrame, min_time, max_time)\n","    \"\"\"\n","    all_user_events = pd.concat(user_subsets.values(), ignore_index=True)\n","    all_user_events[\"event_time\"] = pd.to_datetime(all_user_events[\"event_time\"], errors=\"coerce\")\n","    all_user_events = all_user_events.dropna(subset=[\"event_time\"]).sort_values(\"event_time\")\n","\n","    if all_user_events.empty:\n","        return None, None, None\n","\n","    event_times_sorted = all_user_events[\"event_time\"].tolist()\n","    return all_user_events, event_times_sorted[0], event_times_sorted[-1]\n"],"metadata":{"id":"bLhuI1bcasaw","executionInfo":{"status":"ok","timestamp":1760187516292,"user_tz":-180,"elapsed":3,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["#Excute pipeline"],"metadata":{"id":"MKLzXg7MyI4J"}},{"cell_type":"markdown","source":["##Config and summary"],"metadata":{"id":"rSlSTFM3cYE0"}},{"cell_type":"code","source":["# 1ï¸âƒ£ Load config and all datasets\n","config = load_config(\"/content/drive/MyDrive/Sem-6/coding/github/fraud_detection/configs/baseline.yaml\")\n","data = load_all_data(config)\n","\n","\n","# 2ï¸âƒ£ Extract individual datasets from the returned dictionary\n","df_voc = data[\"voc\"]\n","df_sms = data[\"sms\"]\n","df_app = data[\"app\"]\n","df_user = data[\"user\"]\n","\n","\n","# Voice\n","df_voc[\"source\"] = \"VOC\"\n","df_voc[\"event_time\"] = pd.to_datetime(df_voc.get(\"start_datetime\", df_voc.get(\"event_time\")), errors=\"coerce\")\n","\n","# SMS\n","df_sms[\"source\"] = \"SMS\"\n","df_sms[\"event_time\"] = pd.to_datetime(df_sms.get(\"request_datetime\", df_sms.get(\"event_time\")), errors=\"coerce\")\n","\n","# App\n","df_app[\"source\"] = \"APP\"\n","df_app[\"event_time\"] = pd.to_datetime(df_app[\"event_time\"], errors=\"coerce\")\n","\n","# ARPU (User)\n","df_user[\"source\"] = \"ARPU\"\n","df_user[\"event_time\"] = pd.to_datetime(df_user[\"event_time\"], errors=\"coerce\")\n","\n","print(\"âœ… All datasets standardized and ready for timeline merge:\")\n","print(f\"  VOC  â†’ {len(df_voc):,} records\")\n","print(f\"  SMS  â†’ {len(df_sms):,} records\")\n","print(f\"  APP  â†’ {len(df_app):,} records\")\n","print(f\"  ARPU â†’ {len(df_user):,} records\")\n","\n","\n","df_timeline = build_unified_timeline(df_voc, df_sms, df_app, df_user)\n","\n","# (Optional) Inspect one random user timeline\n","some_user = df_timeline[\"phone_no_m\"].dropna().sample(1).iloc[0]\n","\n","print(f\"ðŸ” Inspecting timeline for user: {some_user}\")\n","user_timeline = df_timeline[df_timeline[\"phone_no_m\"] == some_user]\n","\n","print(f\"Total events for this user: {len(user_timeline)}\")\n","print(user_timeline[\"source\"].value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6qhw9cY6Req","executionInfo":{"status":"ok","timestamp":1760187519415,"user_tz":-180,"elapsed":3121,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}},"outputId":"38e7476b-2e2f-4f3c-805f-3677c2a0afec"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… All datasets standardized and ready for timeline merge:\n","  VOC  â†’ 48,190 records\n","  SMS  â†’ 64,225 records\n","  APP  â†’ 26,142 records\n","  ARPU â†’ 365 records\n","ðŸ“¦ Unified timeline built with 138,922 total events across 60 users.\n","source\n","SMS     64225\n","VOC     48190\n","APP     26142\n","ARPU      365\n","Name: count, dtype: int64\n","ðŸ” Inspecting timeline for user: 5be5a5901aa0e5701f3e6bae83c479c127c48d3b3678084052130f65c38b29a4effe50d2081ed51acc2acf6768005879cc8421086456ae92d8b0aba0fcd6319a\n","Total events for this user: 4106\n","source\n","VOC     1885\n","SMS     1362\n","APP      851\n","ARPU       8\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["##Genrate snapshot"],"metadata":{"id":"gIKJsKelcc8q"}},{"cell_type":"code","source":["\n","save_path = config[\"Agg\"][\"save_path\"]\n","    # Filter invalid ARPU rows\n","\n","for df, label in [(df_user, \"VOC\"), (df_sms, \"SMS\"), (df_app, \"APP\"), (df_user, \"ARPU\")]:\n","            # Normalize event_time field\n","            if \"event_time\" not in df.columns or df[\"event_time\"].isna().all():\n","                for alt_col in [\"start_datetime\", \"request_datetime\", \"date\", \"busi_date\"]:\n","                    if alt_col in df.columns:\n","                        df[\"event_time\"] = pd.to_datetime(df[alt_col], errors=\"coerce\")\n","                        break\n","\n","snapshots_df = build_user_snapshots_global(\n","    df_voc=df_voc,\n","    df_sms=df_sms,\n","    df_app_tx=df_app,\n","    df_arpu_tx=df_user,\n","    window_size=1,\n","    window_mode=\"time\",\n","    max_users=100,\n","    max_snapshots=1\n","\n",")\n","\n","# Save output snapshot\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","os.makedirs(save_path, exist_ok=True)\n","\n","output_file = os.path.join(save_path, f\"user_snapshots_{timestamp}.csv\")\n","snapshots_df.to_csv(output_file, index=False)\n","\n","logger.info(f\"âœ… Feature extraction completed and saved to: {output_file}\")\n","print(f\"âœ… Snapshot file saved to: {output_file}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"GBarLUE4reW1","executionInfo":{"status":"error","timestamp":1760277229882,"user_tz":-180,"elapsed":68,"user":{"displayName":"MUNEER ALNAJDI","userId":"00725468633613892427"}},"outputId":"f5f5dc6d-67f0-45ce-8cc5-31c3b428e3cf"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'config' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3400895168.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Agg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"save_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Filter invalid ARPU rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VOC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_sms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SMS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"APP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ARPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;31m# Normalize event_time field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"]}]}]}